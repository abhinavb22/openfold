[rank: 0] Seed set to 77843
WARNING:root:load from versionmodel_1_multimer_v3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[rank: 0] Seed set to 77843
initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1
wandb: Currently logged in as: abhinav2212 (gohillab). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /scratch/10110/abhinav22/output_dir/wandb/run-20240906_235554-tj1l39cl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run full_train
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gohillab/openfold_training
wandb: üöÄ View run at https://wandb.ai/gohillab/openfold_training/runs/tj1l39cl
Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]

  | Name  | Type          | Params | Mode 
------------------------------------------------
0 | model | AlphaFold     | 93.2 M | train
1 | loss  | AlphaFoldLoss | 0      | train
------------------------------------------------
93.2 M    Trainable params
0         Non-trainable params
93.2 M    Total params
372.895   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1268: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400410390/work/torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
Traceback (most recent call last):
  File "/work/10110/abhinav22/ls6/openfold/train_openfold.py", line 706, in <module>
    main(args)
  File "/work/10110/abhinav22/ls6/openfold/train_openfold.py", line 455, in main
    trainer.fit(
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
    call._call_and_handle_interrupt(
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
    results = self._run_stage()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
    self.fit_loop.run()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 128, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 133, in __next__
    batch = super().__next__()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 60, in __next__
    batch = next(self.iterator)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 142, in __next__
    out = next(self.iterators[0])
  File "/work/10110/abhinav22/ls6/openfold/openfold/data/data_modules.py", line 842, in _batch_prop_gen
    for batch in iterator:
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/work/10110/abhinav22/ls6/openfold/openfold/data/data_modules.py", line 469, in __getitem__
    raise ValueError("Invalid file type")
ValueError: Invalid file type

wandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.016 MB of 0.040 MB uploadedwandb: 
wandb: Run history:
wandb:          AlphaFoldLRScheduler ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb:                         epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    train/chain_center_of_mass ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ
wandb:               train/distogram ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÉ
wandb: train/experimentally_resolved ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ
wandb:                    train/fape ‚ñà‚ñÅ‚ñÇ‚ñá‚ñÜ
wandb:                    train/loss ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ
wandb:              train/masked_msa ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ
wandb:              train/plddt_loss ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ
wandb:          train/supervised_chi ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÅ
wandb:                      train/tm ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÅ
wandb:           train/unscaled_loss ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ
wandb:               train/violation ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÅ
wandb:           trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:          AlphaFoldLRScheduler 0.0
wandb:                         epoch 0
wandb:    train/chain_center_of_mass 0.0
wandb:               train/distogram 1.05469
wandb: train/experimentally_resolved 0.0
wandb:                    train/fape 1.34069
wandb:                    train/loss 46.25
wandb:              train/masked_msa 0.32031
wandb:              train/plddt_loss 0.0
wandb:          train/supervised_chi 0.39062
wandb:                      train/tm 0.0
wandb:           train/unscaled_loss 2.6875
wandb:               train/violation 0.0019
wandb:           trainer/global_step 4
wandb: 
wandb: üöÄ View run full_train at: https://wandb.ai/gohillab/openfold_training/runs/tj1l39cl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/gohillab/openfold_training
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/10110/abhinav22/output_dir/wandb/run-20240906_235554-tj1l39cl/logs
