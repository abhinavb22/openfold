[2024-09-23 14:18:46,461] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,463] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,463] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,474] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,474] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-23 14:18:46,475] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 2
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 1
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[3, 3]
Trainer device info:
  Number of devices: 3
  Number of nodes: 6
WORLD_SIZE: 18
LOCAL_RANK: 0
[1/3] /opt/apps/cuda/12.2/bin/nvcc  -DTORCH_EXTENSION_NAME=evoformer_attn -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/work/10110/abhinav22/ls6/openfold/cutlass/include -I/work/10110/abhinav22/ls6/openfold/cutlass/tools/util/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/TH -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/THC -isystem /opt/apps/cuda/12.2/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DGPU_ARCH=80 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -c /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_cu.cu -o attention_cu.cuda.o 
[2/3] /opt/apps/cuda/12.2/bin/nvcc  -DTORCH_EXTENSION_NAME=evoformer_attn -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/work/10110/abhinav22/ls6/openfold/cutlass/include -I/work/10110/abhinav22/ls6/openfold/cutlass/tools/util/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/TH -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/include/THC -isystem /opt/apps/cuda/12.2/include -isystem /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DGPU_ARCH=80 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -c /work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_back.cu -o attention_back.cuda.o 
[3/3] c++ attention.o attention_back.cuda.o attention_cu.cuda.o -shared -lcurand -L/work/10110/abhinav22/ls6/src/miniforge/envs/openfold_cuda12/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/apps/cuda/12.2/lib64 -lcudart -o evoformer_attn.so
Time to load evoformer_attn op: 322.8732237815857 seconds
Time to load evoformer_attn op: 322.96591329574585 seconds
Time to load evoformer_attn op: 322.9692327976227 seconds
Time to load evoformer_attn op: 330.29514741897583 seconds
Time to load evoformer_attn op: 330.3536100387573 seconds
Time to load evoformer_attn op: 330.3536024093628 seconds
Time to load evoformer_attn op: 330.3535933494568 seconds
Time to load evoformer_attn op: 330.36783719062805 seconds
Time to load evoformer_attn op: 330.3676950931549 seconds
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/56 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/56 [00:00<?, ?it/s] Time to load evoformer_attn op: 331.22051668167114 seconds
Time to load evoformer_attn op: 331.22347140312195 seconds
Time to load evoformer_attn op: 330.16619396209717 seconds
Time to load evoformer_attn op: 330.23826146125793 seconds
Time to load evoformer_attn op: 330.2403678894043 seconds
Time to load evoformer_attn op: 333.88992524147034 seconds
Time to load evoformer_attn op: 338.6268756389618 seconds
Time to load evoformer_attn op: 331.6565089225769 seconds
Time to load evoformer_attn op: 330.2474579811096 seconds
Epoch 0:   2%|â–         | 1/56 [05:54<5:25:24,  0.00it/s]Epoch 0:   2%|â–         | 1/56 [05:55<5:25:26,  0.00it/s, v_num=jamj, train/loss=30.80]Epoch 0:   4%|â–Ž         | 2/56 [06:08<2:45:42,  0.01it/s, v_num=jamj, train/loss=30.80]Epoch 0:   4%|â–Ž         | 2/56 [06:08<2:45:42,  0.01it/s, v_num=jamj, train/loss=64.00]Epoch 0:   5%|â–Œ         | 3/56 [06:26<1:53:44,  0.01it/s, v_num=jamj, train/loss=64.00]Epoch 0:   5%|â–Œ         | 3/56 [06:26<1:53:44,  0.01it/s, v_num=jamj, train/loss=41.00]Epoch 0:   7%|â–‹         | 4/56 [06:41<1:26:54,  0.01it/s, v_num=jamj, train/loss=41.00]Epoch 0:   7%|â–‹         | 4/56 [06:41<1:26:54,  0.01it/s, v_num=jamj, train/loss=46.50]Epoch 0:   9%|â–‰         | 5/56 [06:56<1:10:44,  0.01it/s, v_num=jamj, train/loss=46.50]Epoch 0:   9%|â–‰         | 5/56 [06:56<1:10:44,  0.01it/s, v_num=jamj, train/loss=38.80]Epoch 0:  11%|â–ˆ         | 6/56 [07:07<59:22,  0.01it/s, v_num=jamj, train/loss=38.80]  Epoch 0:  11%|â–ˆ         | 6/56 [07:07<59:22,  0.01it/s, v_num=jamj, train/loss=47.00]Epoch 0:  12%|â–ˆâ–Ž        | 7/56 [07:19<51:13,  0.02it/s, v_num=jamj, train/loss=47.00]Epoch 0:  12%|â–ˆâ–Ž        | 7/56 [07:19<51:13,  0.02it/s, v_num=jamj, train/loss=44.20]Epoch 0:  14%|â–ˆâ–        | 8/56 [07:32<45:15,  0.02it/s, v_num=jamj, train/loss=44.20]Epoch 0:  14%|â–ˆâ–        | 8/56 [07:32<45:15,  0.02it/s, v_num=jamj, train/loss=53.00]Epoch 0:  16%|â–ˆâ–Œ        | 9/56 [07:41<40:11,  0.02it/s, v_num=jamj, train/loss=53.00]Epoch 0:  16%|â–ˆâ–Œ        | 9/56 [07:41<40:11,  0.02it/s, v_num=jamj, train/loss=43.80]Epoch 0:  18%|â–ˆâ–Š        | 10/56 [07:54<36:23,  0.02it/s, v_num=jamj, train/loss=43.80]Epoch 0:  18%|â–ˆâ–Š        | 10/56 [07:54<36:23,  0.02it/s, v_num=jamj, train/loss=63.50]Epoch 0:  20%|â–ˆâ–‰        | 11/56 [08:08<33:17,  0.02it/s, v_num=jamj, train/loss=63.50]Epoch 0:  20%|â–ˆâ–‰        | 11/56 [08:08<33:17,  0.02it/s, v_num=jamj, train/loss=54.00]Epoch 0:  21%|â–ˆâ–ˆâ–       | 12/56 [08:23<30:44,  0.02it/s, v_num=jamj, train/loss=54.00]Epoch 0:  21%|â–ˆâ–ˆâ–       | 12/56 [08:23<30:44,  0.02it/s, v_num=jamj, train/loss=36.20]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 13/56 [09:40<31:59,  0.02it/s, v_num=jamj, train/loss=36.20]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 13/56 [09:40<31:59,  0.02it/s, v_num=jamj, train/loss=64.50]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 14/56 [09:55<29:45,  0.02it/s, v_num=jamj, train/loss=64.50]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 14/56 [09:55<29:45,  0.02it/s, v_num=jamj, train/loss=48.50]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 15/56 [10:04<27:32,  0.02it/s, v_num=jamj, train/loss=48.50]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 15/56 [10:04<27:32,  0.02it/s, v_num=jamj, train/loss=59.80]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 16/56 [10:13<25:34,  0.03it/s, v_num=jamj, train/loss=59.80]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 16/56 [10:13<25:34,  0.03it/s, v_num=jamj, train/loss=38.20]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 17/56 [10:28<24:02,  0.03it/s, v_num=jamj, train/loss=38.20]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 17/56 [10:28<24:02,  0.03it/s, v_num=jamj, train/loss=57.20]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [23:32<49:40,  0.01it/s, v_num=jamj, train/loss=57.20]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [23:32<49:40,  0.01it/s, v_num=jamj, train/loss=46.50]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [23:45<46:15,  0.01it/s, v_num=jamj, train/loss=46.50]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [23:45<46:15,  0.01it/s, v_num=jamj, train/loss=43.00]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [25:23<45:42,  0.01it/s, v_num=jamj, train/loss=43.00]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [25:23<45:42,  0.01it/s, v_num=jamj, train/loss=46.20]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [25:38<42:43,  0.01it/s, v_num=jamj, train/loss=46.20]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [25:38<42:43,  0.01it/s, v_num=jamj, train/loss=54.50]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [25:49<39:54,  0.01it/s, v_num=jamj, train/loss=54.50]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [25:49<39:54,  0.01it/s, v_num=jamj, train/loss=56.00]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [26:02<37:22,  0.01it/s, v_num=jamj, train/loss=56.00]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [26:02<37:22,  0.01it/s, v_num=jamj, train/loss=45.80]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [26:15<35:01,  0.02it/s, v_num=jamj, train/loss=45.80]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [26:15<35:01,  0.02it/s, v_num=jamj, train/loss=33.20]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [26:27<32:48,  0.02it/s, v_num=jamj, train/loss=33.20]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [26:27<32:48,  0.02it/s, v_num=jamj, train/loss=58.50]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [26:36<30:42,  0.02it/s, v_num=jamj, train/loss=58.50]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [26:36<30:42,  0.02it/s, v_num=jamj, train/loss=55.00]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [26:53<28:52,  0.02it/s, v_num=jamj, train/loss=55.00]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [26:53<28:52,  0.02it/s, v_num=jamj, train/loss=35.50]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [27:13<27:13,  0.02it/s, v_num=jamj, train/loss=35.50]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [27:13<27:13,  0.02it/s, v_num=jamj, train/loss=36.20]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [27:28<25:34,  0.02it/s, v_num=jamj, train/loss=36.20]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [27:28<25:34,  0.02it/s, v_num=jamj, train/loss=62.20]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [27:45<24:03,  0.02it/s, v_num=jamj, train/loss=62.20]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [27:45<24:03,  0.02it/s, v_num=jamj, train/loss=46.20]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31/56 [28:01<22:35,  0.02it/s, v_num=jamj, train/loss=46.20]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31/56 [28:01<22:35,  0.02it/s, v_num=jamj, train/loss=63.80]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32/56 [28:16<21:12,  0.02it/s, v_num=jamj, train/loss=63.80]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32/56 [28:16<21:12,  0.02it/s, v_num=jamj, train/loss=35.50]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 33/56 [28:30<19:52,  0.02it/s, v_num=jamj, train/loss=35.50]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 33/56 [28:30<19:52,  0.02it/s, v_num=jamj, train/loss=58.20]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34/56 [28:48<18:38,  0.02it/s, v_num=jamj, train/loss=58.20]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34/56 [28:48<18:38,  0.02it/s, v_num=jamj, train/loss=50.20]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35/56 [33:49<20:17,  0.02it/s, v_num=jamj, train/loss=50.20]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35/56 [33:49<20:17,  0.02it/s, v_num=jamj, train/loss=31.00]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36/56 [34:04<18:55,  0.02it/s, v_num=jamj, train/loss=31.00]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36/56 [34:04<18:55,  0.02it/s, v_num=jamj, train/loss=62.80]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37/56 [34:17<17:36,  0.02it/s, v_num=jamj, train/loss=62.80]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37/56 [34:17<17:36,  0.02it/s, v_num=jamj, train/loss=44.80]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 38/56 [34:34<16:22,  0.02it/s, v_num=jamj, train/loss=44.80]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 38/56 [34:34<16:22,  0.02it/s, v_num=jamj, train/loss=62.80]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39/56 [34:47<15:10,  0.02it/s, v_num=jamj, train/loss=62.80]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39/56 [34:47<15:10,  0.02it/s, v_num=jamj, train/loss=49.80]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/56 [35:02<14:01,  0.02it/s, v_num=jamj, train/loss=49.80]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/56 [35:02<14:01,  0.02it/s, v_num=jamj, train/loss=54.50]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41/56 [35:17<12:54,  0.02it/s, v_num=jamj, train/loss=54.50]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41/56 [35:17<12:54,  0.02it/s, v_num=jamj, train/loss=37.80]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42/56 [35:30<11:50,  0.02it/s, v_num=jamj, train/loss=37.80]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42/56 [35:30<11:50,  0.02it/s, v_num=jamj, train/loss=43.80]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 43/56 [35:40<10:47,  0.02it/s, v_num=jamj, train/loss=43.80]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 43/56 [35:40<10:47,  0.02it/s, v_num=jamj, train/loss=45.80]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44/56 [35:54<09:47,  0.02it/s, v_num=jamj, train/loss=45.80]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44/56 [35:54<09:47,  0.02it/s, v_num=jamj, train/loss=31.00]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 45/56 [38:01<09:17,  0.02it/s, v_num=jamj, train/loss=31.00]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 45/56 [38:01<09:17,  0.02it/s, v_num=jamj, train/loss=46.00]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 46/56 [38:17<08:19,  0.02it/s, v_num=jamj, train/loss=46.00]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 46/56 [38:17<08:19,  0.02it/s, v_num=jamj, train/loss=55.00]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47/56 [38:29<07:22,  0.02it/s, v_num=jamj, train/loss=55.00]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47/56 [38:29<07:22,  0.02it/s, v_num=jamj, train/loss=59.80]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 48/56 [38:43<06:27,  0.02it/s, v_num=jamj, train/loss=59.80]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 48/56 [38:43<06:27,  0.02it/s, v_num=jamj, train/loss=50.50]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49/56 [38:55<05:33,  0.02it/s, v_num=jamj, train/loss=50.50]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49/56 [38:55<05:33,  0.02it/s, v_num=jamj, train/loss=51.50]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 50/56 [39:06<04:41,  0.02it/s, v_num=jamj, train/loss=51.50]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 50/56 [39:06<04:41,  0.02it/s, v_num=jamj, train/loss=59.80]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 51/56 [39:18<03:51,  0.02it/s, v_num=jamj, train/loss=59.80]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 51/56 [39:18<03:51,  0.02it/s, v_num=jamj, train/loss=62.00]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 52/56 [39:29<03:02,  0.02it/s, v_num=jamj, train/loss=62.00]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 52/56 [39:29<03:02,  0.02it/s, v_num=jamj, train/loss=51.50]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53/56 [39:44<02:14,  0.02it/s, v_num=jamj, train/loss=51.50]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53/56 [39:44<02:14,  0.02it/s, v_num=jamj, train/loss=62.00]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 54/56 [39:59<01:28,  0.02it/s, v_num=jamj, train/loss=62.00]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 54/56 [39:59<01:28,  0.02it/s, v_num=jamj, train/loss=38.00]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 55/56 [40:09<00:43,  0.02it/s, v_num=jamj, train/loss=38.00]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 55/56 [40:09<00:43,  0.02it/s, v_num=jamj, train/loss=56.80]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [40:22<00:00,  0.02it/s, v_num=jamj, train/loss=56.80]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [40:22<00:00,  0.02it/s, v_num=jamj, train/loss=56.80]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/56 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/56 [00:00<?, ?it/s][A
Validation DataLoader 0:   2%|â–         | 1/56 [00:07<07:03,  0.13it/s][A
Validation DataLoader 0:   4%|â–Ž         | 2/56 [00:15<06:48,  0.13it/s][A
Validation DataLoader 0:   5%|â–Œ         | 3/56 [00:22<06:38,  0.13it/s][A
Validation DataLoader 0:   7%|â–‹         | 4/56 [00:30<06:41,  0.13it/s][A
Validation DataLoader 0:   9%|â–‰         | 5/56 [00:38<06:31,  0.13it/s][A
Validation DataLoader 0:  11%|â–ˆ         | 6/56 [04:17<35:47,  0.02it/s][A
Validation DataLoader 0:  12%|â–ˆâ–Ž        | 7/56 [04:24<30:54,  0.03it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 8/56 [04:32<27:13,  0.03it/s][A
Validation DataLoader 0:  16%|â–ˆâ–Œ        | 9/56 [04:39<24:20,  0.03it/s][A
Validation DataLoader 0:  18%|â–ˆâ–Š        | 10/56 [04:46<22:00,  0.03it/s][A
Validation DataLoader 0:  20%|â–ˆâ–‰        | 11/56 [04:54<20:04,  0.04it/s][A
Validation DataLoader 0:  21%|â–ˆâ–ˆâ–       | 12/56 [05:01<18:26,  0.04it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 13/56 [05:09<17:02,  0.04it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 14/56 [05:16<15:49,  0.04it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 15/56 [05:24<14:45,  0.05it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–Š       | 16/56 [07:19<18:18,  0.04it/s][A
Validation DataLoader 0:  30%|â–ˆâ–ˆâ–ˆ       | 17/56 [07:26<17:04,  0.04it/s][A
Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [07:34<15:58,  0.04it/s][A
Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [07:41<14:58,  0.04it/s][A
Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [07:48<14:03,  0.04it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [07:56<13:13,  0.04it/s][A
Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [08:03<12:27,  0.05it/s][A
Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [08:11<11:44,  0.05it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [08:18<11:04,  0.05it/s][A
Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [08:26<10:27,  0.05it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [08:33<09:52,  0.05it/s][A
Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [08:40<09:19,  0.05it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [08:48<08:48,  0.05it/s][A
Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [08:55<08:18,  0.05it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [09:03<07:50,  0.06it/s][A
Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31/56 [09:10<07:24,  0.06it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32/56 [09:18<06:58,  0.06it/s][A
Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 33/56 [09:25<06:34,  0.06it/s][A
Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34/56 [09:33<06:11,  0.06it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35/56 [09:40<05:48,  0.06it/s][A
Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36/56 [09:48<05:26,  0.06it/s][A
Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37/56 [09:56<05:06,  0.06it/s][A
Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 38/56 [10:03<04:45,  0.06it/s][A
Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39/56 [10:11<04:26,  0.06it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/56 [10:18<04:07,  0.06it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41/56 [11:23<04:10,  0.06it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42/56 [11:31<03:50,  0.06it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 43/56 [11:38<03:31,  0.06it/s][A
Validation DataLoader 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44/56 [11:45<03:12,  0.06it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 45/56 [11:53<02:54,  0.06it/s][A
Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 46/56 [12:00<02:36,  0.06it/s][A
Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47/56 [12:08<02:19,  0.06it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 48/56 [12:15<02:02,  0.07it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49/56 [12:23<01:46,  0.07it/s][A
Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 50/56 [12:30<01:30,  0.07it/s][A
Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 51/56 [12:38<01:14,  0.07it/s][A
Validation DataLoader 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 52/56 [12:45<00:58,  0.07it/s][A
Validation DataLoader 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53/56 [12:53<00:43,  0.07it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 54/56 [13:00<00:28,  0.07it/s][A
Validation DataLoader 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 55/56 [13:08<00:14,  0.07it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [13:15<00:00,  0.07it/s][A
                                                                        [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [53:40<00:00,  0.02it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [53:40<00:00,  0.02it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 0:   0%|          | 0/56 [00:00<?, ?it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]         Epoch 1:   0%|          | 0/56 [00:00<?, ?it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 1:   2%|â–         | 1/56 [00:37<34:26,  0.03it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 1:   2%|â–         | 1/56 [00:37<34:26,  0.03it/s, v_num=jamj, train/loss=57.20, val/loss=62.50]Epoch 1:   4%|â–Ž         | 2/56 [05:25<2:26:26,  0.01it/s, v_num=jamj, train/loss=57.20, val/loss=62.50]Epoch 1:   4%|â–Ž         | 2/56 [05:25<2:26:27,  0.01it/s, v_num=jamj, train/loss=40.50, val/loss=62.50]Epoch 1:   5%|â–Œ         | 3/56 [05:36<1:39:13,  0.01it/s, v_num=jamj, train/loss=40.50, val/loss=62.50]Epoch 1:   5%|â–Œ         | 3/56 [05:36<1:39:13,  0.01it/s, v_num=jamj, train/loss=31.50, val/loss=62.50]Epoch 1:   7%|â–‹         | 4/56 [05:48<1:15:29,  0.01it/s, v_num=jamj, train/loss=31.50, val/loss=62.50]Epoch 1:   7%|â–‹         | 4/56 [05:48<1:15:29,  0.01it/s, v_num=jamj, train/loss=63.50, val/loss=62.50]Epoch 1:   9%|â–‰         | 5/56 [05:59<1:01:09,  0.01it/s, v_num=jamj, train/loss=63.50, val/loss=62.50]Epoch 1:   9%|â–‰         | 5/56 [05:59<1:01:09,  0.01it/s, v_num=jamj, train/loss=63.20, val/loss=62.50]Epoch 1:  11%|â–ˆ         | 6/56 [06:14<52:00,  0.02it/s, v_num=jamj, train/loss=63.20, val/loss=62.50]  Epoch 1:  11%|â–ˆ         | 6/56 [06:14<52:00,  0.02it/s, v_num=jamj, train/loss=51.80, val/loss=62.50]Epoch 1:  12%|â–ˆâ–Ž        | 7/56 [06:23<44:46,  0.02it/s, v_num=jamj, train/loss=51.80, val/loss=62.50]Epoch 1:  12%|â–ˆâ–Ž        | 7/56 [06:23<44:46,  0.02it/s, v_num=jamj, train/loss=42.50, val/loss=62.50]Epoch 1:  14%|â–ˆâ–        | 8/56 [06:36<39:37,  0.02it/s, v_num=jamj, train/loss=42.50, val/loss=62.50]Epoch 1:  14%|â–ˆâ–        | 8/56 [06:36<39:37,  0.02it/s, v_num=jamj, train/loss=38.50, val/loss=62.50]Epoch 1:  16%|â–ˆâ–Œ        | 9/56 [06:49<35:38,  0.02it/s, v_num=jamj, train/loss=38.50, val/loss=62.50]Epoch 1:  16%|â–ˆâ–Œ        | 9/56 [06:49<35:38,  0.02it/s, v_num=jamj, train/loss=58.00, val/loss=62.50]Epoch 1:  18%|â–ˆâ–Š        | 10/56 [07:04<32:33,  0.02it/s, v_num=jamj, train/loss=58.00, val/loss=62.50]Epoch 1:  18%|â–ˆâ–Š        | 10/56 [07:04<32:33,  0.02it/s, v_num=jamj, train/loss=54.20, val/loss=62.50]Epoch 1:  20%|â–ˆâ–‰        | 11/56 [07:17<29:50,  0.03it/s, v_num=jamj, train/loss=54.20, val/loss=62.50]Epoch 1:  20%|â–ˆâ–‰        | 11/56 [07:17<29:50,  0.03it/s, v_num=jamj, train/loss=59.50, val/loss=62.50]Epoch 1:  21%|â–ˆâ–ˆâ–       | 12/56 [07:41<28:13,  0.03it/s, v_num=jamj, train/loss=59.50, val/loss=62.50]Epoch 1:  21%|â–ˆâ–ˆâ–       | 12/56 [07:41<28:13,  0.03it/s, v_num=jamj, train/loss=30.50, val/loss=62.50]Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 13/56 [07:51<25:58,  0.03it/s, v_num=jamj, train/loss=30.50, val/loss=62.50]Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 13/56 [07:51<25:58,  0.03it/s, v_num=jamj, train/loss=58.50, val/loss=62.50]Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 14/56 [08:00<24:02,  0.03it/s, v_num=jamj, train/loss=58.50, val/loss=62.50]Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 14/56 [08:00<24:02,  0.03it/s, v_num=jamj, train/loss=63.80, val/loss=62.50]Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 15/56 [08:15<22:35,  0.03it/s, v_num=jamj, train/loss=63.80, val/loss=62.50]Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 15/56 [08:15<22:35,  0.03it/s, v_num=jamj, train/loss=49.20, val/loss=62.50]Epoch 1:  29%|â–ˆâ–ˆâ–Š       | 16/56 [08:25<21:03,  0.03it/s, v_num=jamj, train/loss=49.20, val/loss=62.50]Epoch 1:  29%|â–ˆâ–ˆâ–Š       | 16/56 [08:25<21:03,  0.03it/s, v_num=jamj, train/loss=60.00, val/loss=62.50]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 17/56 [15:13<34:56,  0.02it/s, v_num=jamj, train/loss=60.00, val/loss=62.50]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 17/56 [15:13<34:56,  0.02it/s, v_num=jamj, train/loss=61.80, val/loss=62.50]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [15:29<32:41,  0.02it/s, v_num=jamj, train/loss=61.80, val/loss=62.50]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [15:29<32:41,  0.02it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [15:44<30:38,  0.02it/s, v_num=jamj, train/loss=56.80, val/loss=62.50]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [15:44<30:38,  0.02it/s, v_num=jamj, train/loss=40.00, val/loss=62.50]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [38:53<1:10:00,  0.01it/s, v_num=jamj, train/loss=40.00, val/loss=62.50]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [38:53<1:10:00,  0.01it/s, v_num=jamj, train/loss=62.00, val/loss=62.50]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [39:06<1:05:11,  0.01it/s, v_num=jamj, train/loss=62.00, val/loss=62.50]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [39:06<1:05:11,  0.01it/s, v_num=jamj, train/loss=62.50, val/loss=62.50]Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [39:20<1:00:47,  0.01it/s, v_num=jamj, train/loss=62.50, val/loss=62.50]Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [39:20<1:00:47,  0.01it/s, v_num=jamj, train/loss=36.80, val/loss=62.50]Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [39:31<56:42,  0.01it/s, v_num=jamj, train/loss=36.80, val/loss=62.50]  Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [39:31<56:42,  0.01it/s, v_num=jamj, train/loss=60.80, val/loss=62.50]Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [39:41<52:54,  0.01it/s, v_num=jamj, train/loss=60.80, val/loss=62.50]Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [39:41<52:54,  0.01it/s, v_num=jamj, train/loss=59.20, val/loss=62.50]Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [39:54<49:29,  0.01it/s, v_num=jamj, train/loss=59.20, val/loss=62.50]Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [39:54<49:29,  0.01it/s, v_num=jamj, train/loss=62.20, val/loss=62.50]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [40:12<46:23,  0.01it/s, v_num=jamj, train/loss=62.20, val/loss=62.50]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [40:12<46:23,  0.01it/s, v_num=jamj, train/loss=40.80, val/loss=62.50]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [40:27<43:27,  0.01it/s, v_num=jamj, train/loss=40.80, val/loss=62.50]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [40:27<43:27,  0.01it/s, v_num=jamj, train/loss=37.50, val/loss=62.50]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [40:42<40:42,  0.01it/s, v_num=jamj, train/loss=37.50, val/loss=62.50]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [40:42<40:42,  0.01it/s, v_num=jamj, train/loss=30.60, val/loss=62.50]Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [40:57<38:07,  0.01it/s, v_num=jamj, train/loss=30.60, val/loss=62.50]Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [40:57<38:07,  0.01it/s, v_num=jamj, train/loss=57.20, val/loss=62.50]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [41:12<35:42,  0.01it/s, v_num=jamj, train/loss=57.20, val/loss=62.50]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [41:12<35:42,  0.01it/s, v_num=jamj, train/loss=48.50, val/loss=62.50]Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31/56 [41:27<33:26,  0.01it/s, v_num